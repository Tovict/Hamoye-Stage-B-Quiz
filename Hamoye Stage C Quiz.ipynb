{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c02bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary librabries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321058e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e408f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab40099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(r'C:\\Users\\IE CONNECT.DESKTOP-KDL44I3\\Downloads\\Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c57c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac64ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "205607df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03490380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With this output there is no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99694f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to instruction, we are to drop stab column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d6c9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.drop(columns='stab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05df425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting our dataset into 80-20 training and testing set\n",
    "#And using 1 as our random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a421ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stabf'], axis = 1)\n",
    "y = df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dbb8ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stabf.value_counts() #Before spliting, checking stable and unstable value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f8704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to split\n",
    "#Importing librabries and assigning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09aa8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a3b204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    5092\n",
       "stable      2908\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb9a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    1288\n",
       "stable       712\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5814907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to instruction, we are to transform using StandardScaler\n",
    "#Importing the standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e25d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb40ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a522e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_train = scaler.fit_transform(X_train)\n",
    "transformed_X_train = pd.DataFrame(transformed_X_train, columns =X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fda81d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367327</td>\n",
       "      <td>-0.986042</td>\n",
       "      <td>0.650447</td>\n",
       "      <td>1.547527</td>\n",
       "      <td>-0.291490</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>1.293862</td>\n",
       "      <td>-0.845074</td>\n",
       "      <td>0.160918</td>\n",
       "      <td>0.339859</td>\n",
       "      <td>0.585568</td>\n",
       "      <td>0.492239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064659</td>\n",
       "      <td>0.089437</td>\n",
       "      <td>1.035079</td>\n",
       "      <td>-1.641494</td>\n",
       "      <td>0.619865</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.502925</td>\n",
       "      <td>0.486613</td>\n",
       "      <td>-0.293143</td>\n",
       "      <td>-1.558488</td>\n",
       "      <td>1.429649</td>\n",
       "      <td>-1.443521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.467850</td>\n",
       "      <td>1.298418</td>\n",
       "      <td>-0.502536</td>\n",
       "      <td>1.166046</td>\n",
       "      <td>-0.180521</td>\n",
       "      <td>0.490603</td>\n",
       "      <td>0.682560</td>\n",
       "      <td>-0.855302</td>\n",
       "      <td>1.399350</td>\n",
       "      <td>1.451534</td>\n",
       "      <td>-1.045743</td>\n",
       "      <td>0.492489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.820081</td>\n",
       "      <td>0.529920</td>\n",
       "      <td>1.299657</td>\n",
       "      <td>-1.141975</td>\n",
       "      <td>-0.812854</td>\n",
       "      <td>-0.763632</td>\n",
       "      <td>1.521579</td>\n",
       "      <td>0.658780</td>\n",
       "      <td>-0.958319</td>\n",
       "      <td>1.361958</td>\n",
       "      <td>1.604140</td>\n",
       "      <td>0.275303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.665424</td>\n",
       "      <td>-1.425627</td>\n",
       "      <td>0.312300</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>-1.614296</td>\n",
       "      <td>0.760315</td>\n",
       "      <td>1.422019</td>\n",
       "      <td>0.639243</td>\n",
       "      <td>1.676895</td>\n",
       "      <td>0.695660</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>-1.312575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  0.367327 -0.986042  0.650447  1.547527 -0.291490  0.061535  1.293862   \n",
       "1 -0.064659  0.089437  1.035079 -1.641494  0.619865 -0.067235 -1.502925   \n",
       "2 -1.467850  1.298418 -0.502536  1.166046 -0.180521  0.490603  0.682560   \n",
       "3  0.820081  0.529920  1.299657 -1.141975 -0.812854 -0.763632  1.521579   \n",
       "4  0.665424 -1.425627  0.312300  0.919137 -1.614296  0.760315  1.422019   \n",
       "\n",
       "         p4        g1        g2        g3        g4  \n",
       "0 -0.845074  0.160918  0.339859  0.585568  0.492239  \n",
       "1  0.486613 -0.293143 -1.558488  1.429649 -1.443521  \n",
       "2 -0.855302  1.399350  1.451534 -1.045743  0.492489  \n",
       "3  0.658780 -0.958319  1.361958  1.604140  0.275303  \n",
       "4  0.639243  1.676895  0.695660  1.137504 -1.312575  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_train.head()  #checking output after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afbc3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf1b4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_test = scaler.fit_transform(X_test)\n",
    "transformed_X_test = pd.DataFrame(transformed_X_test, columns =X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4306e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.592163</td>\n",
       "      <td>-0.420565</td>\n",
       "      <td>1.472472</td>\n",
       "      <td>1.093036</td>\n",
       "      <td>0.426786</td>\n",
       "      <td>-1.504594</td>\n",
       "      <td>-0.792677</td>\n",
       "      <td>1.600201</td>\n",
       "      <td>-0.925703</td>\n",
       "      <td>1.175287</td>\n",
       "      <td>-1.492644</td>\n",
       "      <td>1.086291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.199183</td>\n",
       "      <td>0.364543</td>\n",
       "      <td>-0.190076</td>\n",
       "      <td>-0.518473</td>\n",
       "      <td>-0.229402</td>\n",
       "      <td>-1.071766</td>\n",
       "      <td>0.427103</td>\n",
       "      <td>1.052337</td>\n",
       "      <td>-1.655910</td>\n",
       "      <td>-0.395949</td>\n",
       "      <td>1.412703</td>\n",
       "      <td>1.227535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.086035</td>\n",
       "      <td>-0.321834</td>\n",
       "      <td>-0.873505</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>-0.977094</td>\n",
       "      <td>0.094896</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>1.450284</td>\n",
       "      <td>-1.444370</td>\n",
       "      <td>0.654216</td>\n",
       "      <td>-1.679799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.087014</td>\n",
       "      <td>-1.113357</td>\n",
       "      <td>0.361518</td>\n",
       "      <td>-1.684316</td>\n",
       "      <td>0.792280</td>\n",
       "      <td>-1.649041</td>\n",
       "      <td>0.410662</td>\n",
       "      <td>-0.084473</td>\n",
       "      <td>0.066085</td>\n",
       "      <td>-1.679450</td>\n",
       "      <td>-0.349573</td>\n",
       "      <td>1.057439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.873004</td>\n",
       "      <td>1.425833</td>\n",
       "      <td>0.080476</td>\n",
       "      <td>1.681022</td>\n",
       "      <td>-0.154247</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>-0.197525</td>\n",
       "      <td>0.485988</td>\n",
       "      <td>0.119716</td>\n",
       "      <td>-1.475773</td>\n",
       "      <td>0.957057</td>\n",
       "      <td>-0.817608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  0.592163 -0.420565  1.472472  1.093036  0.426786 -1.504594 -0.792677   \n",
       "1  0.199183  0.364543 -0.190076 -0.518473 -0.229402 -1.071766  0.427103   \n",
       "2 -1.086035 -0.321834 -0.873505  0.011761 -0.977094  0.094896  0.813041   \n",
       "3 -0.087014 -1.113357  0.361518 -1.684316  0.792280 -1.649041  0.410662   \n",
       "4  0.873004  1.425833  0.080476  1.681022 -0.154247 -0.024315 -0.197525   \n",
       "\n",
       "         p4        g1        g2        g3        g4  \n",
       "0  1.600201 -0.925703  1.175287 -1.492644  1.086291  \n",
       "1  1.052337 -1.655910 -0.395949  1.412703  1.227535  \n",
       "2  0.751381  1.450284 -1.444370  0.654216 -1.679799  \n",
       "3 -0.084473  0.066085 -1.679450 -0.349573  1.057439  \n",
       "4  0.485988  0.119716 -1.475773  0.957057 -0.817608  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_test.head()  #checking output after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b08c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to instruction, we are asked to use sklearn to train random forest and extra trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1de3125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing our classifier and fitting in the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75d68b",
   "metadata": {},
   "source": [
    "# QUESTION 4\n",
    "What is the accuracy on the test set using the random forest classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26a38bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rf = RandomForestClassifier(random_state=1)\n",
    "classifier_rf.fit(transformed_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cd04208",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = classifier_rf.predict(transformed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00765236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'stable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd2ceaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Metrics\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ed7a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.928\n",
      "Precision score for label stable 0.918\n",
      "Recall score for label stable 0.8764044943820225\n",
      "F1 score 0.897\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score {}\".format(accuracy_score(y_test, predicts)))\n",
    "print(\"Precision score for label stable %.3f\" % (precision_score(y_test, predicts, pos_label='stable')))\n",
    "print(\"Recall score for label stable {}\".format(recall_score(y_test, predicts, pos_label='stable')))\n",
    "print(\"F1 score %.3f\" % (f1_score(y_test, predicts, pos_label='stable')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2002c612",
   "metadata": {},
   "source": [
    "# QUESTION 1\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d669176",
   "metadata": {},
   "source": [
    "When evaluating classification modelling and difference between test and training error is a big positive number\n",
    "with a low training error. The problem facing is;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc48a68",
   "metadata": {},
   "source": [
    "Answer: Overfitting and High Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb6371",
   "metadata": {},
   "source": [
    "# QUESTION 2\n",
    "As a Data Scientist, that trained 4 Models to solve this use case:\n",
    "\n",
    "Keeping the following evaluation criteria in mind:\n",
    "\n",
    "1) Must have a recall rate of at least 80% \n",
    "\n",
    "2) Must have a false positive rate of 8% or less \n",
    "\n",
    "3) Must minimize business costs\n",
    "\n",
    " After creating each binary classification model and generating the corresponding confusion matrix. The confusion matrix that represents the model are:\n",
    " \n",
    "ANSWER: TN = 98%, FP = 2%, FN = 18%, TP = 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be79c95",
   "metadata": {},
   "source": [
    "# QUESTION 5\n",
    "What is the accuracy on the test set using the LGBM classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea3a9080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "lgbm = lgbm.LGBMClassifier(random_state=1)\n",
    "lgbm.fit(transformed_X_train,y_train)\n",
    "lgbm_predicts = lgbm.predict(transformed_X_test)\n",
    "lgbm_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d2ea727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9365"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, lgbm_predicts),4) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "770c06dc",
   "metadata": {},
   "source": [
    "ANSWER : 0.9365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d30f24",
   "metadata": {},
   "source": [
    "# QUESTION 6\n",
    "\n",
    "What is the entropy of the target variable if its actual values are given as:\n",
    "\n",
    "[1,0,1,1,0,1,0]\n",
    "\n",
    "Entropy: -E p(x)*log p(x)\n",
    "\n",
    "We have seven observations(four ones and three zeros)\n",
    "\n",
    "Using the formular - 3/7 log(3/7) - 4/7 log(4/7)\n",
    "\n",
    "ANSWER: - 3/7 log(4/7) + 4/7 log(3/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8788ca",
   "metadata": {},
   "source": [
    "# QUESTION 7\n",
    "What is the F1 score of this classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "885fa5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2635658914728682\n"
     ]
    }
   ],
   "source": [
    "#Total instances (n) = 1700\n",
    "# F1 is given as 2 * (Precision*Recall)/(Precision + Recall)\n",
    "# From the confusion matrix we have;\n",
    "\n",
    "Precision = (255/ ( 255+1380)) \n",
    "Recall =  (255 /(255+45)) \n",
    "F1_Score = 2 * (Precision*Recall)/(Precision + Recall)\n",
    "print(F1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f4e2f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2636"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(F1_Score,4) #Rounding off to 4DP"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e724b01",
   "metadata": {},
   "source": [
    "ANSWER: 0.2636"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd48013",
   "metadata": {},
   "source": [
    "# QUESTION 8\n",
    "Why do we use weak learners in boosting, instead if strong learners?\n",
    "\n",
    "ANSWER: To prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22202f3",
   "metadata": {},
   "source": [
    "# QUESTION 9\n",
    "\n",
    "A medical company is building a model to predict the occurrence of thyroid cancer. \n",
    "The training data contains 900 negative instances (people who don't have cancer) and 100 positive instances.\n",
    "The resulting model has 90% accuracy, but extremely poor recall. \n",
    "What steps can be used to improve the model's performance\n",
    "                                                   \n",
    "ANSWER: Generate synthetic samples/data using SMOTE\n",
    "\n",
    "        Use Boosting algorithm                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d62e18",
   "metadata": {},
   "source": [
    "# QUESTION 10\n",
    "ANSWER:The model has no discrimination capacity to differentiate between the positive and the negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d01903f",
   "metadata": {},
   "source": [
    "# QUESTION 11\n",
    "\n",
    "ANSWER: RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6748c",
   "metadata": {},
   "source": [
    "# QUESTION 12\n",
    "\n",
    "What is the accuracy on the test set using the XGboost classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01e2566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xg_c = XGBClassifier(random_state =1)\n",
    "xg_c.fit(transformed_X_train, y_train)\n",
    "xg_c_pred = xg_c.predict(transformed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2ffea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.94      0.91      0.92       712\n",
      "    unstable       0.95      0.97      0.96      1288\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.94      0.94      0.94      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, xg_c_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d292ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test,xg_c_pred),4)  #rounding Accuracy to 4DP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2f663",
   "metadata": {},
   "source": [
    "# QUESTION 13\n",
    "\n",
    "Using the ExtraTreesClassifier as your estimator with cv=5, n_iter=10, scoring = 'accuracy',\n",
    "n_jobs = -1, verbose = 1 and random_state = 1. What are the best hyperparameters from the randomized search CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e947c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "Tree_CLass = ExtraTreesClassifier (random_state = 1) \n",
    "\n",
    "n_estimators = [50, 100, 300, 500, 1000]    \n",
    "\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "                       'min_samples_split': min_samples_split,\n",
    "\n",
    "                       'max_features': max_features}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3904c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "Rand_search = RandomizedSearchCV(estimator = Tree_CLass, param_distributions= hyperparameter_grid, random_state=1,cv = 5, \n",
    "                                 n_iter=10,scoring='accuracy',n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "524e93e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "search = Rand_search.fit(transformed_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bc8456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd9699",
   "metadata": {},
   "source": [
    "# QUESTION 14\n",
    "Which of the following metric is generally NOT useful for a classification problem?\n",
    "\n",
    "ANSWER: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a091b",
   "metadata": {},
   "source": [
    "# QUESTION 15\n",
    "Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the most and least important respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c1ac524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13723975 0.1405075  0.13468029 0.13541676 0.00368342 0.00533686\n",
      " 0.00542927 0.00496249 0.10256244 0.10757765 0.11306268 0.10954089]\n"
     ]
    }
   ],
   "source": [
    "feat_import = search.best_estimator_.feature_importances_\n",
    "print ( feat_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d26b279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.14050750384993677, 'tau2'),\n",
       " (0.13723974766109256, 'tau1'),\n",
       " (0.1354167630909727, 'tau4'),\n",
       " (0.13468028520386593, 'tau3'),\n",
       " (0.11306267999167334, 'g3'),\n",
       " (0.10954089174337298, 'g4'),\n",
       " (0.10757764577478764, 'g2'),\n",
       " (0.10256244080927947, 'g1'),\n",
       " (0.005429268421191957, 'p3'),\n",
       " (0.005336864710946151, 'p2'),\n",
       " (0.004962486591192238, 'p4'),\n",
       " (0.003683422151688322, 'p1')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted (zip(feat_import,X), reverse = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1ef92d1",
   "metadata": {},
   "source": [
    "ANSWER : With the output 'tau2' and 'p1' are the most and least important features respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911eb0c",
   "metadata": {},
   "source": [
    "# QUESTION 16\n",
    "\n",
    "Which of these is not a good metric for evaluating classification algorithms for data with imbalanced class problems?\n",
    "\n",
    "ANSWER: ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8f0fc",
   "metadata": {},
   "source": [
    "# QUESTION 17\n",
    "What other hyperparameter optimization method can you try apart from Random Search?\n",
    "\n",
    "ANSWER: GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6ac65",
   "metadata": {},
   "source": [
    "# QUESTION 18\n",
    "\n",
    "You are building a classifier and the accuracy is poor on both the training and test sets. \n",
    "Which would you use to try to improve the performance?\n",
    "\n",
    "ANSWER: BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3c386",
   "metadata": {},
   "source": [
    "# QUESTION 19\n",
    "\n",
    "The number predicted with the least accuracy is 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28df68",
   "metadata": {},
   "source": [
    "# QUESTION 20\n",
    "\n",
    "You are developing a machine learning classification algorithm that categorizes handwritten digits 0-9 into the numbers they represent. How should you pre-process the label data?\n",
    "\n",
    "ANSWER: One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa94469",
   "metadata": {},
   "source": [
    "# QUESTION 3\n",
    "\n",
    "Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). \n",
    "Is the accuracy of the new optimal model higher or lowerthan the initial ExtraTreesClassifier model with no\n",
    "hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a479667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=1000, min_samples_split=2,  min_samples_leaf=8, max_features=None)\n",
    "etc.fit(transformed_X_train, y_train)\n",
    "etc = etc.predict(transformed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aca7c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.92      0.87      0.90       712\n",
      "    unstable       0.93      0.96      0.94      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.92      0.92      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score 0.928\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,etc)) \n",
    "print('\\n')\n",
    "print(\"Accuracy score {}\".format(accuracy_score(y_test, etc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cce1beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.94      0.85      0.89       712\n",
      "    unstable       0.92      0.97      0.94      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.91      0.92      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMPARING THIS RESULT \n",
    "\n",
    "Tree_CLass.fit(transformed_X_train,y_train)\n",
    "Tree_predict = Tree_CLass.predict(transformed_X_test)\n",
    "\n",
    "print(classification_report(y_test,Tree_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bd6b685",
   "metadata": {},
   "source": [
    " ANSWER: It is lower with the comparison done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c343dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
